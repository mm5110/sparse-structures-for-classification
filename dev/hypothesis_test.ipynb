{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Test - does joint sparsity bring any benefit?\n",
    "In this notebook we examine weather joint sparsity has any benefit over standard sparse coding techniques for classification. The rough idea is that a joint sparse forward pass will learn a code or representation for the a data point that takes into account other examples of the same class. In effect then we are trying to map all members of a given class onto a particular subspace. To test the benefits we consider two tests:\n",
    "- classification: we perform classification by taking the set of sparse representations of a class and then perform SVD, so as to identify say the top 5 singular vectors that span a linear space that in some sense represents the given class label in the encoder space. We benchmark against standard IHT and PCA.\n",
    "- reconstruction / decoding: we observe the reconstruction rate for JIHT vs IHT and PCA. It is expected that IHT should have a better reconstruction error.\n",
    "\n",
    "\n",
    "## Methodology\n",
    "### For classification:\n",
    "For the IHT/ JIHT:\n",
    "- we train a model on MNIST with an IHT/ JIHT forward pass\n",
    "- we then run the entire MNIST traing set through the modelto find all the training data point encodings\n",
    "- group the encodings by class, and carry out SVD to find the j singular vectors. These j linear vectors define a linear manifold or subspace which we 'associate' with the class\n",
    "- then run the entire test set through the model to find all the test data point encodings\n",
    "- classify each test data point by assigning into the class whose linear manifold or subspace is closest to the data points encoding by projecting\n",
    "\n",
    "PCA benchmarking approach:\n",
    "- Find the j principal components of the training data set for each class\n",
    "- Project the test data onto each of the sets of j principal components of each class\n",
    "- Assign a test data point to the class for which it has the largest projection (shortest distance) \n",
    "\n",
    "Then compare them all by looking at the percentage of data points that they correctly categorised.\n",
    "\n",
    "### For reconstruction:\n",
    "For the IHT/ JIHT:\n",
    "- Simple: forward pass and then reverse pass, calculate l2 distance between decoded and original data point. Calculate the percentage error over the entire test set and training set. Also plot to inpect visually\n",
    "\n",
    "PCA benchmarking approach:\n",
    "- Calculate the m principal components of the training data set (these act as our atoms)\n",
    "- For each data point encode it as the sum of the K principal components that the data point is closest (calculate the inner product between the data point and each principal component, select largest K\n",
    "- reconstruct data point or image from just these K principal components\n",
    "\n",
    "Compare the total reconstruction error betweenIHT, JIHT and PCA for both the test and training data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MNIST Data\n",
    "First script simply imports the MNIST training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "import random\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "rep_batch_size = 60000\n",
    "test_batch_size = 5000\n",
    "\n",
    "# Dimension of class subspace\n",
    "l = 10\n",
    "\n",
    "# Sparsity value for pca\n",
    "numb_atoms = 500\n",
    "K=50\n",
    "\n",
    "# Load MNIST\n",
    "root = './data'\n",
    "download = True  # download MNIST dataset or not\n",
    "\n",
    "# Access MNIST dataset and define processing transforms to proces\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# trans = transforms.Compose([transforms.ToTensor()])\n",
    "train_set = dsets.MNIST(root=root, train=True, transform=trans, download=download)\n",
    "test_set = dsets.MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=rep_batch_size,\n",
    "                 sampler = None,\n",
    "                 shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=test_batch_size,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run data on through IHT Model:\n",
    "Firstly just load the IHT model and check few examples to inspect weather it is working as it should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load mode\n",
    "importlib.reload(aux)\n",
    "\n",
    "model = aux.load_model(model_filename)\n",
    "\n",
    "# model.mask = torch.ones(N_TEST_IMG, m)\n",
    "\n",
    "# Check that reconstructions etc. are working as they\n",
    "fig = plt.figure(figsize=(5, 2))\n",
    "# original data (first row) for viewing\n",
    "view_data = Variable(train_data.train_data[:N_TEST_IMG].view(-1, 28*28).type(torch.FloatTensor)/255.)\n",
    "view_data = view_data.to(device)\n",
    "decoded, encoded, nnz = model2(view_data,int(25))\n",
    "\n",
    "for i in range(N_TEST_IMG):\n",
    "    plt.subplot(2,N_TEST_IMG,i+1)\n",
    "    plt.imshow(np.reshape(view_data.cpu().data.numpy()[i], (28, 28)), cmap='gray')\n",
    "\n",
    "for i in range(N_TEST_IMG):\n",
    "    plt.subplot(2,N_TEST_IMG,i+6)\n",
    "    plt.imshow(np.reshape(decoded.cpu().data.numpy()[i], (28, 28)), cmap='gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly we just runthe entire training data set through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
