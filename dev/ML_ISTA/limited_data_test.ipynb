{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limited data test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this notebook is to provide a rig to test and compare the performance of the bench mark NN, ML-ISTA and ML-JISTA network in terms of their ability to efficiently learn weight parameters to minimise empirical test error. Testing involves training the a number of these networks with varying numbers of training data points made available. Idea is perhaps that JISTA can act as a 'camel' in terms of leading fewer training data points to do a good job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import time\n",
    "import progressbar\n",
    "import importlib\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "\n",
    "import Models_MNIST as mds\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 35\n",
    "BATCH_SIZE = 256\n",
    "DOWNLOAD_MNIST = False\n",
    "m1 = 64\n",
    "m2 = 128\n",
    "m3 = 512\n",
    "cudaopt = True\n",
    "\n",
    "EPS = 1e-4\n",
    "\n",
    "# Mnist digits dataset\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../data',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=True,                        # download it if you don't have it\n",
    ")\n",
    "\n",
    "numb_train = [512, 1024, 4096, 10e3, 20e3, 60e3]\n",
    "train_data_sets = []\n",
    "\n",
    "# LIMITING TRAINING DATA\n",
    "\n",
    "for i in range len(numb_train):\n",
    "    train_set = np.random.permutation(numb_train[i])[0:Ntrain]\n",
    "    train_data.train_data = train_data.train_data[torch.LongTensor(train_set),:,:]\n",
    "    train_data.train_labels = train_data.train_labels[torch.LongTensor(train_set)]\n",
    "    train_data_sets.append(train_data)\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='../data',\n",
    "    train=False,                                     # this is testing data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=True,                        # download it if you don't have it\n",
    ")\n",
    "\n",
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Loss_test_baseline = np.zeros((EPOCH, numb_train))\n",
    "Acc_test_baseline = np.zeros((EPOCH, numb_train))\n",
    "\n",
    "Loss_test_ISTA = np.zeros((EPOCH, numb_train))\n",
    "Acc_test_ISTA = np.zeros((EPOCH, numb_train))\n",
    "\n",
    "Loss_test_JISTA = np.zeros((EPOCH, numb_train))\n",
    "Acc_test_JISTA = np.zeros((EPOCH, numb_train))\n",
    "\n",
    "print('\\n\\t\\t\\t\\t\\tTraining Baseline \\n')\n",
    "\n",
    "# Iterate through each of the training data set sizes\n",
    "for i in range(numb_train):\n",
    "    print(\"Training and testing models with training data size of \")\n",
    "    # Load data for the correct size\n",
    "    train_loader = Data.DataLoader(dataset=train_data_sets[i], batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    # Define the three models we want to compare     \n",
    "    model_baseline = mds.ML_ISTA_NET(m1,m2,m3)\n",
    "    model_ISTA = mds.ML_ISTA_NET(m1,m2,m3)\n",
    "    model_JISTA = mds.ML_JISTA_NET(m1,m2,m3)\n",
    "    \n",
    "    # Optimise if CUDA is available   \n",
    "    if cudaopt:\n",
    "        model_baseline.cuda()\n",
    "        model_ISTA.cuda()\n",
    "        model_JISTA.cuda()\n",
    "    \n",
    "    # Define optimizer for each model to update a specific model's parameters    \n",
    "    optimizer_baseline = torch.optim.Adam(model_baseline.parameters(), lr = 0.0001, eps = EPS)\n",
    "    optimizer_ISTA = torch.optim.Adam(model_ISTA.parameters(), lr = 0.0001, eps = EPS)\n",
    "    optimizer_JISTA = torch.optim.Adam(model_JISTA.parameters(), lr = 0.0001, eps = EPS)\n",
    "    \n",
    "    bar = progressbar.ProgressBar()\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "\n",
    "        bar.update((epoch+1)/EPOCH*100)\n",
    "        \n",
    "        # train each model for 1 epoch\n",
    "        model_baseline.train()\n",
    "        model_ISTA.train()\n",
    "        model_JISTA.train()\n",
    "        \n",
    "        for step, (x, y) in enumerate(train_loader):\n",
    "            b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "            b_y = Variable(y)               # batch label\n",
    "            if cudaopt:\n",
    "                b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "            # Run data through each model                \n",
    "            encoded_baseline, scores_baseline = model_baseline(b_x)\n",
    "            encoded_ISTA, scores_ISTA = model_ISTA(b_x)\n",
    "            encoded_JISTA, scores_JISTA = model_JISTA.joint_train(b_x)\n",
    "            # Calculate the training loss for each model and backprop\n",
    "            # BASELINE            \n",
    "            loss_baseline = F.nll_loss(scores, b_y)      # negative log likelyhood\n",
    "            optimizer_baseline.zero_grad()               # clear gradients for this training step\n",
    "            loss_baseline.backward()                     # backpropagation, compute gradients\n",
    "            optimizer_baseline.step()                    # apply gradients\n",
    "            # ISTA            \n",
    "            loss_baseline = F.nll_loss(scores, b_y)      # negative log likelyhood\n",
    "            optimizer_baseline.zero_grad()               # clear gradients for this training step\n",
    "            loss_baseline.backward()                     # backpropagation, compute gradients\n",
    "            optimizer_baseline.step()                    # apply gradients\n",
    "            # JISTA\n",
    "            loss_baseline = F.nll_loss(scores, b_y)      # negative log likelyhood\n",
    "            optimizer_baseline.zero_grad()               # clear gradients for this training step\n",
    "            loss_baseline.backward()                     # backpropagation, compute gradients\n",
    "            optimizer_baseline.step()                    # apply gradients\n",
    "        \n",
    "        # TEST EACH MODEL AND STORE PERFORMANCE\n",
    "        model_baseline.eval()\n",
    "        model_ISTA.eval()\n",
    "        model_JISTA.eval()     \n",
    "        correct_baseline = 0\n",
    "        correct_ISTA = 0\n",
    "        correct_JISTA = 0       \n",
    "        test_loss_baseline = 0\n",
    "        test_loss_ISTA = 0\n",
    "        test_loss_JISTA = 0\n",
    "        for step, (x, y) in enumerate(test_loader):\n",
    "            b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "            b_y = Variable(y)               # batch label\n",
    "            if cudaopt:\n",
    "                b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "            # Calculate the test loss for each model\n",
    "            gamma, scores = model_baseline(b_x)\n",
    "            test_loss_baseline += F.nll_loss(scores, b_y, size_average=False).data[0]\n",
    "            pred = scores.data.max(1, keepdim=True)[1]\n",
    "            correct_baseline += pred.eq(b_y.data.view_as(pred)).long().cpu().sum()\n",
    "            test_loss_ISTA += F.nll_loss(scores, b_y, size_average=False).data[0]\n",
    "            pred = scores.data.max(1, keepdim=True)[1]\n",
    "            correct_ISTA += pred.eq(b_y.data.view_as(pred)).long().cpu().sum()\n",
    "            test_loss_JISTA += F.nll_loss(scores, b_y, size_average=False).data[0]\n",
    "            pred = scores.data.max(1, keepdim=True)[1]\n",
    "            correct_ISTA += pred.eq(b_y.data.view_as(pred)).long().cpu().sum()\n",
    "        \n",
    "        # Calculate each error as a percentage\n",
    "        test_loss_baseline /= len(test_loader.dataset)\n",
    "        test_loss_ISTA /= len(test_loader.dataset)\n",
    "        test_loss_JISTA /= len(test_loader.dataset)\n",
    "        \n",
    "        Loss_test_baseline[epoch,i] = test_loss_baseline\n",
    "        Acc_test_baseline[epoch,i] =  100 * float(correct_baseline) /float(len(test_loader.dataset))\n",
    "        \n",
    "        Loss_test_ISTA[epoch,i] = test_loss_ISTA\n",
    "        Acc_test_ISTA[epoch,i] =  100 * float(correct_ISTA) /float(len(test_loader.dataset))\n",
    "        \n",
    "        Loss_test_JISTA[epoch,i] = test_loss_JISTA\n",
    "        Acc_test_JISTA[epoch,i] =  100 * float(correct_JISTA) /float(len(test_loader.dataset))\n",
    "\n",
    "#     torch.save(model.state_dict(), 'cnn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.style.use('default')\n",
    "plt.plot(Acc_test_baseline[], linewidth = 2,label='baseline')\n",
    "plt.plot(Acc_test_ista_r, linewidth = 2,label = 'ML-ISTA')\n",
    "plt.plot(Acc_test_jista_r, linewidth = 2,label = 'ML-JISTA')\n",
    "# plt.plot(Acc_test_fista_r, linewidth = 2,label = 'ML-FISTA')\n",
    "\n",
    "plt.grid('on')\n",
    "plt.title('Test Accuracy - 4 Unfoldings')\n",
    "plt.legend()\n",
    "plt.axis([0, 100, 95, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
