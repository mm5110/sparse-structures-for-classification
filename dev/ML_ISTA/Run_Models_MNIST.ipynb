{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import time\n",
    "import progressbar\n",
    "import importlib\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "\n",
    "import Models_MNIST as mds\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 256\n",
    "DOWNLOAD_MNIST = False\n",
    "m1 = 64\n",
    "m2 = 128\n",
    "m3 = 512\n",
    "cudaopt = True\n",
    "\n",
    "EPS = 1e-4\n",
    "\n",
    "# Mnist digits dataset\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../data',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=True,                        # download it if you don't have it\n",
    ")\n",
    "\n",
    "# LIMITING TRAINING DATA\n",
    "Ntrain = int(60e3)\n",
    "train_set = np.random.permutation(60000)[0:Ntrain]\n",
    "train_data.train_data = train_data.train_data[torch.LongTensor(train_set),:,:]\n",
    "train_data.train_labels = train_data.train_labels[torch.LongTensor(train_set)]\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='../data',\n",
    "    train=False,                                     # this is testing data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=True,                        # download it if you don't have it\n",
    ")\n",
    "\n",
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f658d273d30>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(1,EPOCH,EPOCH)\n",
    "Rhos = 1/(1+np.exp(-(x- EPOCH*6/9 )*.2))\n",
    "plt.plot(Rhos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\t\t\tTraining Baseline\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ |#                                                  | 0 Elapsed Time: 0:00:00/anaconda/envs/mlvm/lib/python3.6/site-packages/ipykernel/__main__.py:39: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-89ab4c21b5ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mb_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# batch x, shape (batch, 28*28)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mb_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# batch label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/mlvm/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/mlvm/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/mlvm/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/mlvm/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \"\"\"\n\u001b[0;32m-> 2421\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2423\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Loss_test_0 = np.zeros((EPOCH,))\n",
    "Acc_test_0 = np.zeros((EPOCH,))\n",
    "\n",
    "print('\\n\\t\\t\\t\\t\\tTraining Baseline\\n')\n",
    "    \n",
    "model = mds.ML_ISTA_NET(m1,m2,m3)\n",
    "if cudaopt:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, eps = EPS)\n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    bar.update((epoch+1)/EPOCH*100)\n",
    "    # train 1 epoch\n",
    "    model.train()\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        encoded, scores = model(b_x)\n",
    "        loss = F.nll_loss(scores, b_y)      # negative log likelyhood\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "\n",
    "    # testing\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    for step, (x, y) in enumerate(test_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        gamma, scores = model(b_x)\n",
    "        test_loss += F.nll_loss(scores, b_y, size_average=False).data[0]\n",
    "        pred = scores.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(b_y.data.view_as(pred)).long().cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    Loss_test_0[epoch] = test_loss\n",
    "    Acc_test_0[epoch] =  100 * float(correct) /float(len(test_loader.dataset))\n",
    "    \n",
    "torch.save(model.state_dict(), 'cnn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-JISTA TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(mds)\n",
    "\n",
    "# T = 0\n",
    "# RHO =  float(Rhos[0])\n",
    "\n",
    "# dataiter = iter(train_loader)\n",
    "# x, labels = dataiter.next()\n",
    "\n",
    "# model = mds.ML_JISTA_NET(m1,m2,m3)\n",
    "# x = Variable(x)# batch x, shape (batch, 28*28)\n",
    "# labels = Variable(labels)\n",
    "# # print(x.shape)\n",
    "# # print(labels.shape)\n",
    "\n",
    "# temp = np.empty(labels.shape[0])\n",
    "# # print(temp.shape)\n",
    "\n",
    "# encoded, scores, sorted_labels = model.joint_train(x, labels, T, RHO)\n",
    "\n",
    "# # print(scores.shape)\n",
    "# # print(sorted_labels.shape)\n",
    "# # print(type(scores))\n",
    "# # print(type(sorted_labels))\n",
    "\n",
    "# loss = F.nll_loss(scores, sorted_labels)  \n",
    "# optimizer.zero_grad()               \n",
    "# loss.backward()                     \n",
    "# optimizer.step()\n",
    "\n",
    "# X1 = torch.rand(4,6,1,1)\n",
    "# X1_dims = list(X1.shape)\n",
    "# X1_mat = X1.view(-1, X1_dims[1])\n",
    "# st_factors = 1-2/(torch.sum(X1_mat**2, dim=0))\n",
    "# st_factors_mat = torch.diag(st_factors)\n",
    "# X2_mat = F.relu(torch.t(torch.mm(st_factors_mat, torch.t(X1_mat))))\n",
    "# X2 = X2_mat.view(X1_dims[0], X1_dims[1], X1_dims[2], X1_dims[3])\n",
    "# print(X1_mat)\n",
    "# print(X2_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-JISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(mds)\n",
    "\n",
    "Loss_test_ista_r = np.zeros((EPOCH,))\n",
    "Acc_test_jista_r = np.zeros((EPOCH,))\n",
    "\n",
    "print('\\n\\t\\t\\t\\t\\tTraining ML-JISTA \\n')\n",
    "\n",
    "T = 4  # number of unfoldings/iterations of ml-ista\n",
    "\n",
    "model = mds.ML_JISTA_NET(m1,m2,m3)\n",
    "if cudaopt:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, eps = EPS)\n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "#     print(\"Epoch: \" + str(int(epoch)))\n",
    "    bar.update((epoch+1)/EPOCH*100)\n",
    "    # train 1 epoch\n",
    "    model.train()\n",
    "    \n",
    "    RHO =  float(Rhos[epoch])\n",
    "    \n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        encoded, scores, sorted_labels = model.joint_train(b_x, b_y, T, RHO)\n",
    "#         print(type(sorted_labels))\n",
    "        sorted_labels = sorted_labels.type(torch.cuda.LongTensor)\n",
    "#         scores = scores.type(torch.cuda.LongTensor)\n",
    "#         print(type(sorted_labels))\n",
    "        scores.type(torch.cuda.LongTensor)\n",
    "#         print(scores.shape)\n",
    "#         print(b_y.shape)\n",
    "        \n",
    "        loss = F.nll_loss(scores, sorted_labels)      # negative log likelyhood\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "#         print(loss)\n",
    "    # testing\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    for step, (x, y) in enumerate(test_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        gamma, scores = model.forward(b_x,T,RHO)\n",
    "        test_loss += F.nll_loss(scores, b_y, size_average=False).data[0]\n",
    "        pred = scores.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(b_y.data.view_as(pred)).long().cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    Loss_test_ista_r[epoch] = test_loss\n",
    "    Acc_test_jista_r[epoch] =  100 * float(correct) /float(len(test_loader.dataset))\n",
    "#     print(\"Performance at epoch \" + str(int(epoch)) + \": \" + str(Acc_test_ista_r[epoch]))\n",
    "    \n",
    "torch.save(model.state_dict(), 'mljista_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-ISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_test_ista_r = np.zeros((EPOCH,))\n",
    "Acc_test_ista_r = np.zeros((EPOCH,))\n",
    "\n",
    "print('\\n\\t\\t\\t\\t\\tTraining ML-ISTA \\n')\n",
    "\n",
    "T = 4  # number of unfoldings/iterations of ml-ista\n",
    "\n",
    "model = mds.ML_ISTA_NET(m1,m2,m3)\n",
    "if cudaopt:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, eps = EPS)\n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "#     print(\"Epoch: \" + str(int(epoch)))\n",
    "    bar.update((epoch+1)/EPOCH*100)\n",
    "    # train 1 epoch\n",
    "    model.train()\n",
    "    \n",
    "    RHO =  float(Rhos[epoch])\n",
    "    \n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        encoded, scores = model(b_x,T,RHO)\n",
    "        \n",
    "#         print(scores.shape)\n",
    "#         print(b_y.shape)\n",
    "        \n",
    "        loss = F.nll_loss(scores, b_y)      # negative log likelyhood\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "\n",
    "    # testing\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    for step, (x, y) in enumerate(test_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        gamma, scores = model(b_x,T,RHO)\n",
    "        test_loss += F.nll_loss(scores, b_y, size_average=False).data[0]\n",
    "        pred = scores.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(b_y.data.view_as(pred)).long().cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    Loss_test_ista_r[epoch] = test_loss\n",
    "    Acc_test_ista_r[epoch] =  100 * float(correct) /float(len(test_loader.dataset))\n",
    "    \n",
    "torch.save(model.state_dict(), 'mlista_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### ML-FISTA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Loss_test_fista_r = np.zeros((EPOCH,))\n",
    "Acc_test_fista_r = np.zeros((EPOCH,))\n",
    "\n",
    "print('\\n\\t\\t\\t\\t\\tTraining ML-FISTA \\n')\n",
    "\n",
    "model = mds.ML_FISTA_NET(m1,m2,m3)\n",
    "if cudaopt:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, eps = EPS)\n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    bar.update((epoch+1)/EPOCH*100)\n",
    "    # train 1 epoch\n",
    "    model.train()\n",
    "    \n",
    "    RHO = float(Rhos[epoch])\n",
    "    \n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        encoded, scores = model(b_x,T,RHO)\n",
    "        loss = F.nll_loss(scores, b_y)      # negative log likelyhood\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "\n",
    "    # testing\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    for step, (x, y) in enumerate(test_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        gamma, scores = model(b_x,T,RHO)\n",
    "        test_loss += F.nll_loss(scores, b_y, size_average=False).data[0]\n",
    "        pred = scores.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(b_y.data.view_as(pred)).long().cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    Loss_test_fista_r[epoch] = test_loss\n",
    "    Acc_test_fista_r[epoch] =  100 * float(correct) /float(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.style.use('default')\n",
    "plt.plot(Acc_test_0, linewidth = 2,label='baseline')\n",
    "plt.plot(Acc_test_ista_r, linewidth = 2,label = 'ML-ISTA')\n",
    "plt.plot(Acc_test_jista_r, linewidth = 2,label = 'ML-JISTA')\n",
    "# plt.plot(Acc_test_fista_r, linewidth = 2,label = 'ML-FISTA')\n",
    "\n",
    "plt.grid('on')\n",
    "plt.title('Test Accuracy - 4 Unfoldings')\n",
    "plt.legend()\n",
    "plt.axis([0, 100, 95, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
