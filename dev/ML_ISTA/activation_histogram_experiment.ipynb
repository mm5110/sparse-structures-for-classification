{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import time\n",
    "import progressbar\n",
    "import importlib\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "\n",
    "import Models_MNIST as mds\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 256\n",
    "DOWNLOAD_MNIST = False\n",
    "\n",
    "m1 = 64\n",
    "m2 = 128\n",
    "m3 = 50\n",
    "cudaopt = True\n",
    "\n",
    "EPS = 1e-4\n",
    "\n",
    "# Mnist digits dataset\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../data',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=True,                        # download it if you don't have it\n",
    ")\n",
    "\n",
    "# LIMITING TRAINING DATA\n",
    "Ntrain = int(60e3)\n",
    "train_set = np.random.permutation(60000)[0:Ntrain]\n",
    "train_data.train_data = train_data.train_data[torch.LongTensor(train_set),:,:]\n",
    "train_data.train_labels = train_data.train_labels[torch.LongTensor(train_set)]\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='../data',\n",
    "    train=False,                                     # this is testing data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=True,                        # download it if you don't have it\n",
    ")\n",
    "\n",
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define models normal neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_net(nn.Module):\n",
    "    def __init__(self,m1,m2,m3):\n",
    "        super(neural_net, self).__init__()\n",
    "        \n",
    "        # Convolutional Filters\n",
    "        self.W1 = nn.Parameter(torch.randn(m1,1,6,6), requires_grad=True)\n",
    "        self.strd1 = 2;\n",
    "        self.W2 = nn.Parameter(torch.randn(m2,m1,6,6), requires_grad=True)\n",
    "        self.strd2 = 2;\n",
    "        self.W3 = nn.Parameter(torch.randn(m3,m2,4,4), requires_grad=True)\n",
    "        self.strd3 = 1;\n",
    "        \n",
    "        # Biases / Thresholds\n",
    "        self.b1 = nn.Parameter(torch.zeros(1,m1,1,1), requires_grad=True)\n",
    "        self.b2 = nn.Parameter(torch.zeros(1,m2,1,1), requires_grad=True)\n",
    "        self.b3 = nn.Parameter(torch.zeros(1,m3,1,1), requires_grad=True)\n",
    "        \n",
    "        # Classifier\n",
    "        self.Wclass = nn.Linear(m3, 10)\n",
    "        \n",
    "        # Initialization\n",
    "        self.W1.data = 0.01 * self.W1.data\n",
    "        self.W2.data = 0.01 * self.W2.data\n",
    "        self.W3.data = 0.01 * self.W3.data\n",
    "        \n",
    "    def forward(self, x):    \n",
    "        # Encoding\n",
    "        gamma1 = F.relu(F.conv2d(x,self.W1, stride = self.strd1) + self.b1)       # first estimation\n",
    "        gamma2 = F.relu(F.conv2d(gamma1,self.W2, stride = self.strd2) + self.b2) \n",
    "        gamma3 = F.relu(F.conv2d(gamma2,self.W3, stride = self.strd3) + self.b3)\n",
    "        activation1 = gamma1.clone()\n",
    "        activation1[activation1!=0]=1\n",
    "        activation2 = gamma1.clone()\n",
    "        activation2[activation2!=0]=1\n",
    "        activation3 = gamma3.clone()\n",
    "        activation3[activation3!=0]=1\n",
    "        # classifier\n",
    "        gamma = gamma3.view(gamma3.shape[0],gamma3.shape[1]*gamma3.shape[2]*gamma3.shape[3])\n",
    "        out = self.Wclass(gamma)\n",
    "        out = F.log_softmax(out,dim = 1)\n",
    "        # calculate activations for each layer          \n",
    "        \n",
    "        # classifier\n",
    "        gamma = gamma3.view(gamma3.shape[0],gamma3.shape[1]*gamma3.shape[2]*gamma3.shape[3])\n",
    "        out = self.Wclass(gamma)\n",
    "        scores = F.log_softmax(out, dim = 1)\n",
    "    \n",
    "        return gamma, scores, activation1, activation2, activation3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define joint neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class joint_neural_net(nn.Module):\n",
    "    def __init__(self,m1,m2,m3):\n",
    "        super(joint_neural_net, self).__init__()\n",
    "        \n",
    "        # Convolutional Filters\n",
    "        self.W1 = nn.Parameter(torch.randn(m1,1,6,6), requires_grad=True)\n",
    "        self.strd1 = 2;\n",
    "        self.W2 = nn.Parameter(torch.randn(m2,m1,6,6), requires_grad=True)\n",
    "        self.strd2 = 2;\n",
    "        self.W3 = nn.Parameter(torch.randn(m3,m2,4,4), requires_grad=True)\n",
    "        self.strd3 = 1;\n",
    "        \n",
    "        # Biases / Thresholds\n",
    "        self.b1 = nn.Parameter(torch.zeros(1,m1,1,1), requires_grad=True)\n",
    "        self.b2 = nn.Parameter(torch.zeros(1,m2,1,1), requires_grad=True)\n",
    "        self.b3 = nn.Parameter(torch.zeros(1,m3,1,1), requires_grad=True)\n",
    "        \n",
    "        # Classifier\n",
    "        self.Wclass = nn.Linear(m3, 10)\n",
    "        \n",
    "        # Initialization\n",
    "        self.W1.data = 0.01 * self.W1.data\n",
    "        self.W2.data = 0.01 * self.W2.data\n",
    "        self.W3.data = 0.01 * self.W3.data\n",
    "        \n",
    "        \n",
    "    def forward(self, x):    \n",
    "        # Encoding\n",
    "        gamma1 = F.relu(F.conv2d(x,self.W1, stride = self.strd1) + self.b1)       # first estimation\n",
    "        gamma2 = F.relu(F.conv2d(gamma1,self.W2, stride = self.strd2) + self.b2) \n",
    "        gamma3 = F.relu(F.conv2d(gamma2,self.W3, stride = self.strd3) + self.b3)\n",
    "        # classifier\n",
    "        gamma = gamma3.view(gamma3.shape[0],gamma3.shape[1]*gamma3.shape[2]*gamma3.shape[3])\n",
    "        out = self.Wclass(gamma)\n",
    "        out = F.log_softmax(out,dim = 1)\n",
    "        # calculate activations for each layer          \n",
    "        activation1 = gamma1.clone()\n",
    "        activation1[activation1!=0]=1\n",
    "        activation2 = gamma1.clone()\n",
    "        activation2[activation2!=0]=1\n",
    "        activation3 = gamma3.clone()\n",
    "        activation3[activation3!=0]=1\n",
    "        \n",
    "        # classifier\n",
    "        gamma = gamma3.view(gamma3.shape[0],gamma3.shape[1]*gamma3.shape[2]*gamma3.shape[3])\n",
    "        out = self.Wclass(gamma)\n",
    "        out = F.log_softmax(out,dim = 1)\n",
    "    \n",
    "        return gamma, out, activation1, activation2, activation3\n",
    "    \n",
    "    def joint_train(self, x, labels):\n",
    "        # print(\"Running joint training\")\n",
    "        # Initialise dics to contain sorted data\n",
    "        label_bin_data = {\"0\":[], \"1\":[], \"2\":[], \"3\":[], \"4\":[], \"5\":[], \"6\":[], \"7\":[], \"8\":[], \"9\":[]} # Dictionary of lists of tensors\n",
    "        data_by_class = {} # Dictionary of tensors\n",
    "        encoded_by_class = {} # Dictionary of tensors\n",
    "        scores_by_class = {} # Dictionary of lists\n",
    "        sorted_labels = np.empty(labels.shape[0])\n",
    "        index = 0\n",
    "        # Sort data by its label class into a dictionary of lists which contain the data point tensors\n",
    "        for i in range(labels.shape[0]):\n",
    "            label_bin_data[str(int(labels[i].item()))].append(x[i,:,:,:])\n",
    "        # Turn each list of tensors in the dictionary into a tensor\n",
    "        first = True\n",
    "        for key, tensor_list in label_bin_data.items():\n",
    "            # print(key)\n",
    "            # print(len(label_bin_data[key]))\n",
    "            if len(label_bin_data[key]) > 0:\n",
    "                sorted_labels[index:index+len(label_bin_data[key])] = int(key)*np.ones(len(label_bin_data[key]))\n",
    "                index = index+len(label_bin_data[key])\n",
    "                data_by_class[key] = torch.stack(label_bin_data[key], dim=0)\n",
    "                encoded_by_class[key], scores_by_class[key] = self.joint_forward(data_by_class[key])\n",
    "                if first == True:\n",
    "                    scores = scores_by_class[key]\n",
    "                    first = False\n",
    "                else:\n",
    "                    scores = torch.cat((scores, scores_by_class[key]), 0)\n",
    "        return encoded_by_class, scores, torch.from_numpy(sorted_labels).type(torch.LongTensor)\n",
    "    \n",
    "\n",
    "    def joint_forward(self,x):   \n",
    "        # Encoding\n",
    "        gamma1 = F.relu(F.conv2d(x,self.W1, stride = self.strd1) + self.b1)       # first estimation\n",
    "        gamma2 = F.relu(F.conv2d(gamma1,self.W2, stride = self.strd2) + self.b2)\n",
    "        \n",
    "        # Encourage joint sparisty in the final layer sparse layer encoding\n",
    "        X1 = F.conv2d(gamma2,self.W3, stride = self.strd3)\n",
    "        X1_dims = list(X1.shape)\n",
    "        X1_mat = X1.view(-1, X1_dims[1])\n",
    "        st_factors = 1-torch.squeeze(self.b3)*1/(torch.sum(X1_mat**2, dim=0))\n",
    "        st_factors_mat = torch.diag(st_factors)\n",
    "        X2_mat = torch.t(torch.mm(st_factors_mat, torch.t(X1_mat)))\n",
    "        X2 = X2_mat.view(X1_dims[0], X1_dims[1], X1_dims[2], X1_dims[3])    \n",
    "        gamma3 = F.relu(X2)\n",
    "        \n",
    "        # classifier\n",
    "        gamma = gamma3.view(gamma3.shape[0],gamma3.shape[1]*gamma3.shape[2]*gamma3.shape[3])\n",
    "        out = self.Wclass(gamma)\n",
    "        out = F.log_softmax(out,dim = 1)\n",
    "    \n",
    "        return gamma, out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x, labels):\n",
    "    # Initialise dics to contain sorted data\n",
    "    label_bin_data = {\"0\":[], \"1\":[], \"2\":[], \"3\":[], \"4\":[], \"5\":[], \"6\":[], \"7\":[], \"8\":[], \"9\":[]} # Dictionary of lists of tensors\n",
    "    data_by_class = {} # Dictionary of tensors\n",
    "    encoded_by_class = {} # Dictionary of tensors\n",
    "    scores_by_class = {} # Dictionary of lists\n",
    "    sorted_labels = np.empty(labels.shape[0])\n",
    "    index = 0\n",
    "    \n",
    "    activations_count1 = {}\n",
    "    activations_count2 = {}\n",
    "    activations_count3 = {}\n",
    "    \n",
    "    # Sort data by its label class into a dictionary of lists which contain the data point tensors\n",
    "    for i in range(labels.shape[0]):\n",
    "        label_bin_data[str(int(labels[i].item()))].append(x[i,:,:,:])\n",
    "    # Turn each list of tensors in the dictionary into a tensor\n",
    "    first = True\n",
    "    for key, tensor_list in label_bin_data.items():\n",
    "        # print(key)\n",
    "        # print(len(label_bin_data[key]))\n",
    "        if len(label_bin_data[key]) > 0:\n",
    "            sorted_labels[index:index+len(label_bin_data[key])] = int(key)*np.ones(len(label_bin_data[key]))\n",
    "            index = index+len(label_bin_data[key])\n",
    "            data_by_class[key] = torch.stack(label_bin_data[key], dim=0)\n",
    "            encoded_by_class[key], scores_by_class[key], activations1, activations2, activations3 = model(data_by_class[key])\n",
    "            activations_count1[key] = torch.sum(activations1.view(-1, m1), dim=0)\n",
    "            activations_count2[key] = torch.sum(activations2.view(-1, m2), dim=0)\n",
    "            activations_count3[key] = torch.sum(activations3.view(-1, m3), dim=0)\n",
    "            if first == True:\n",
    "                scores = scores_by_class[key]\n",
    "                first = False\n",
    "            else:\n",
    "                scores = torch.cat((scores, scores_by_class[key]), 0)\n",
    "    return encoded_by_class, scores, torch.from_numpy(sorted_labels).type(torch.LongTensor), activations_count1, activations_count2, activations_count3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train baseline neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\t\t\tTraining Baseline\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ |#                                                  | 0 Elapsed Time: 0:00:00/anaconda/envs/mlvm/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/ |                         #                        | 50 Elapsed Time: 0:00:52"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-263474d71cd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcudaopt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mb_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mencoded_by_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0msorted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactivations1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ca1b8fb34eb2>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, x, labels)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_bin_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdata_by_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_bin_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mencoded_by_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_by_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_by_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mactivations_count1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mactivations_count2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/mlvm/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-3d92bbecd0c0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mgamma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrd2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mgamma3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrd3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mactivation1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mactivation1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactivation1\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mactivation2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "Loss_test_nn = np.zeros((EPOCH,))\n",
    "Acc_test_nn = np.zeros((EPOCH,))\n",
    "\n",
    "print('\\n\\t\\t\\t\\t\\tTraining Baseline\\n')\n",
    "    \n",
    "model = neural_net(m1,m2,m3)\n",
    "\n",
    "activations_count1_nn = {\"0\": torch.zeros(m1), \"1\":torch.zeros(m1), \"2\":torch.zeros(m1), \"3\":torch.zeros(m1), \"4\":torch.zeros(m1), \"5\":torch.zeros(m1), \"6\":torch.zeros(m1), \"7\":torch.zeros(m1), \"8\":torch.zeros(m1), \"9\":torch.zeros(m1)}\n",
    "activations_count2_nn = {\"0\": torch.zeros(m2), \"1\":torch.zeros(m2), \"2\":torch.zeros(m2), \"3\":torch.zeros(m2), \"4\":torch.zeros(m2), \"5\":torch.zeros(m2), \"6\":torch.zeros(m2), \"7\":torch.zeros(m2), \"8\":torch.zeros(m2), \"9\":torch.zeros(m2)}\n",
    "activations_count3_nn = {\"0\": torch.zeros(m3), \"1\":torch.zeros(m3), \"2\":torch.zeros(m3), \"3\":torch.zeros(m3), \"4\":torch.zeros(m3), \"5\":torch.zeros(m3), \"6\":torch.zeros(m3), \"7\":torch.zeros(m3), \"8\":torch.zeros(m3), \"9\":torch.zeros(m3)}\n",
    "\n",
    "if cudaopt:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, eps = EPS)\n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    bar.update((epoch+1)/EPOCH*100)\n",
    "    # train 1 epoch\n",
    "    model.train()\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        encoded, scores,_,_,_ = model(b_x)\n",
    "        loss = F.nll_loss(scores, b_y)      # negative log likelyhood\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients      \n",
    "            \n",
    "    # testing\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    for step, (x, y) in enumerate(test_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        encoded_by_class, scores, sorted_labels, activations1, activations2, activations3 = test(model, b_x, b_y)\n",
    "        sorted_labels = sorted_labels.type(torch.cuda.LongTensor)\n",
    "        for key, tensor_list in activations1.items():\n",
    "            activations_count1_nn[key] += activations1[key].type(torch.FloatTensor)\n",
    "            activations_count2_nn[key] += activations2[key].type(torch.FloatTensor)\n",
    "            activations_count3_nn[key] += activations3[key].type(torch.FloatTensor)\n",
    "                \n",
    "        test_loss += F.nll_loss(scores, sorted_labels, size_average=False).data[0]\n",
    "        pred = scores.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(b_y.data.view_as(pred)).long().cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    Loss_test_nn[epoch] = test_loss\n",
    "    Acc_test_nn[epoch] =  100 * float(correct) /float(len(test_loader.dataset))\n",
    "    \n",
    "torch.save(model.state_dict(), 'cnn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Joint Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_test_jnn = np.zeros((EPOCH,))\n",
    "Acc_test_jnn = np.zeros((EPOCH,))\n",
    "\n",
    "print('\\n\\t\\t\\t\\t\\tTraining Baseline\\n')\n",
    "    \n",
    "model = joint_neural_net(m1,m2,m3)\n",
    "\n",
    "activations_count1_jnn = {\"0\": torch.zeros(m1), \"1\":torch.zeros(m1), \"2\":torch.zeros(m1), \"3\":torch.zeros(m1), \"4\":torch.zeros(m1), \"5\":torch.zeros(m1), \"6\":torch.zeros(m1), \"7\":torch.zeros(m1), \"8\":torch.zeros(m1), \"9\":torch.zeros(m1)}\n",
    "activations_count2_jnn = {\"0\": torch.zeros(m2), \"1\":torch.zeros(m2), \"2\":torch.zeros(m2), \"3\":torch.zeros(m2), \"4\":torch.zeros(m2), \"5\":torch.zeros(m2), \"6\":torch.zeros(m2), \"7\":torch.zeros(m2), \"8\":torch.zeros(m2), \"9\":torch.zeros(m2)}\n",
    "activations_count3_jnn = {\"0\": torch.zeros(m3), \"1\":torch.zeros(m3), \"2\":torch.zeros(m3), \"3\":torch.zeros(m3), \"4\":torch.zeros(m3), \"5\":torch.zeros(m3), \"6\":torch.zeros(m3), \"7\":torch.zeros(m3), \"8\":torch.zeros(m3), \"9\":torch.zeros(m3)}\n",
    "\n",
    "if cudaopt:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, eps = EPS)\n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    bar.update((epoch+1)/EPOCH*100)\n",
    "    # train 1 epoch\n",
    "    model.train()\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        encoded, scores, sorted_labels = model.joint_train(b_x, b_y)\n",
    "        sorted_labels = sorted_labels.type(torch.cuda.LongTensor)\n",
    "        loss = F.nll_loss(scores, sorted_labels)      # negative log likelyhood\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients      \n",
    "            \n",
    "    # testing\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    for step, (x, y) in enumerate(test_loader):\n",
    "        b_x = Variable(x)   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(y)               # batch label\n",
    "        if cudaopt:\n",
    "            b_y, b_x = b_y.cuda(), b_x.cuda()\n",
    "        encoded_by_class, scores, sorted_labels, activations1, activations2, activations3 = test(model, b_x, b_y)\n",
    "        sorted_labels = sorted_labels.type(torch.cuda.LongTensor)\n",
    "        for key, tensor_list in activations1.items():\n",
    "            activations_count1_jnn[key] += activations1[key].type(torch.FloatTensor)\n",
    "            activations_count2_jnn[key] += activations2[key].type(torch.FloatTensor)\n",
    "            activations_count3_jnn[key] += activations3[key].type(torch.FloatTensor)\n",
    "                \n",
    "        test_loss += F.nll_loss(scores, sorted_labels, size_average=False).data[0]\n",
    "        pred = scores.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(b_y.data.view_as(pred)).long().cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    Loss_test_jnn[epoch] = test_loss\n",
    "    Acc_test_jnn[epoch] =  100 * float(correct) /float(len(test_loader.dataset))\n",
    "    \n",
    "torch.save(model.state_dict(), 'cnn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.style.use('default')\n",
    "plt.plot(Acc_test_nn, linewidth = 2,label='Normal')\n",
    "plt.plot(Acc_test_jnn, linewidth = 2,label = 'Joint')\n",
    "plt.grid('on')\n",
    "plt.title('Test Accuracy')\n",
    "plt.ylabel('Classification accuracy %')\n",
    "plt.xlabel('# Epochs')\n",
    "plt.legend()\n",
    "plt.axis([0, EPOCH-1, 0, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histrograms of activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = 9\n",
    "idx2 = 1\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.bar(np.arange(m3), activations_count3_jnn[str(idx1)].detach().numpy())\n",
    "plt.title('Joint NN histogram of layer 3 activations - number:' + str(idx1))\n",
    "plt.xlabel('Node index')\n",
    "plt.ylabel('# activations')\n",
    "plt.subplot(2,2,2)\n",
    "plt.bar(np.arange(m3), activations_count3_nn[str(idx1)].detach().numpy())\n",
    "plt.title('NN histogram of layer 3 activations - number:' + str(idx1))\n",
    "plt.xlabel('Node index')\n",
    "plt.ylabel('# activations')\n",
    "plt.subplot(2,2,3)\n",
    "plt.bar(np.arange(m3), activations_count3_jnn[str(idx2)].detach().numpy())\n",
    "plt.title('Joint NN histogram of layer 3 activations - number:' + str(idx2))\n",
    "plt.xlabel('Node index')\n",
    "plt.ylabel('# activations')\n",
    "plt.subplot(2,2,4)\n",
    "plt.bar(np.arange(m3), activations_count3_nn[str(idx2)].detach().numpy())\n",
    "plt.title('NN histogram of layer 3 activations - number:' + str(idx2))\n",
    "plt.xlabel('Node index')\n",
    "plt.ylabel('# activations')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative visualisations of activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlvm)",
   "language": "python",
   "name": "mlvm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
